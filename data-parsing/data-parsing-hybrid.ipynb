{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd28973c",
   "metadata": {},
   "source": [
    "# Old Bailey Corpus Data Parsing - Hybrid Pipeline\n",
    "This notebook extends the standard data parsing pipeline by extracting additional metadata for the hybrid classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89863828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867e12dd",
   "metadata": {},
   "source": [
    "## Parse XML and Extract Data with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "153003c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing complete! 100088 rows extracted\n",
      "\n",
      "Metadata columns: ['Trial_ID', 'Date', 'Defendant_Surname', 'Defendant_Given', 'Defendant_Gender', 'Num_Defendants', 'Victim_Surname', 'Victim_Given', 'Victim_Gender', 'Num_Victims', 'Verdict', 'Punishment', 'Offence', 'Offence_Subcategory', 'Crime_Date', 'Trial_Text']\n"
     ]
    }
   ],
   "source": [
    "xml_folder = \"../dataset/OBC2/\"\n",
    "xml_files = glob.glob(os.path.join(xml_folder, \"*.xml\"))\n",
    "data = []\n",
    "\n",
    "for file in xml_files:\n",
    "    tree = ET.parse(file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for trial in root.findall(\".//div1[@type='trialAccount']\"):\n",
    "        trial_id = trial.get(\"id\", \"Unknown\")\n",
    "        trial_date_element = trial.find(\"interp[@type='date']\")\n",
    "        trial_date = trial_date_element.get(\"value\", \"Unknown\") if trial_date_element is not None else \"Unknown\"\n",
    "\n",
    "        # Extract defendant information\n",
    "        defendants = trial.findall(\".//persName[@type='defendantName']\")\n",
    "        num_defendants = len(defendants)\n",
    "        defendant_genders = []\n",
    "        surname, given = \"Unknown\", \"Unknown\"\n",
    "        \n",
    "        for defendant in defendants:\n",
    "            gender_element = defendant.find(\"interp[@type='gender']\")\n",
    "            if gender_element is not None:\n",
    "                defendant_genders.append(gender_element.get(\"value\", \"Unknown\"))\n",
    "            if surname == \"Unknown\":\n",
    "                surname_element = defendant.find(\"interp[@type='surname']\")\n",
    "                surname = surname_element.get(\"value\", \"Unknown\") if surname_element is not None else \"Unknown\"\n",
    "                given_element = defendant.find(\"interp[@type='given']\")\n",
    "                given = given_element.get(\"value\", \"Unknown\") if given_element is not None else \"Unknown\"\n",
    "        \n",
    "        # Determine primary defendant gender\n",
    "        if defendant_genders:\n",
    "            defendant_gender = defendant_genders[0]\n",
    "        else:\n",
    "            defendant_gender = \"Unknown\"\n",
    "\n",
    "        # Extract victim information\n",
    "        victims = trial.findall(\".//persName[@type='victimName']\")\n",
    "        num_victims = len(victims)\n",
    "        victim_genders = []\n",
    "        victim_surname, victim_given = \"Unknown\", \"Unknown\"\n",
    "        \n",
    "        for victim in victims:\n",
    "            gender_element = victim.find(\"interp[@type='gender']\")\n",
    "            if gender_element is not None:\n",
    "                victim_genders.append(gender_element.get(\"value\", \"Unknown\"))\n",
    "            if victim_surname == \"Unknown\":\n",
    "                victim_surname_element = victim.find(\"interp[@type='surname']\")\n",
    "                victim_surname = victim_surname_element.get(\"value\", \"Unknown\") if victim_surname_element is not None else \"Unknown\"\n",
    "                victim_given_element = victim.find(\"interp[@type='given']\")\n",
    "                victim_given = victim_given_element.get(\"value\", \"Unknown\") if victim_given_element is not None else \"Unknown\"\n",
    "        \n",
    "        # Determine primary victim gender\n",
    "        if victim_genders:\n",
    "            victim_gender = victim_genders[0]\n",
    "        else:\n",
    "            victim_gender = \"Unknown\"\n",
    "\n",
    "        # Extract verdict\n",
    "        verdict = trial.find(\".//rs[@type='verdictDescription']/interp[@type='verdictCategory']\")\n",
    "        verdict_text = verdict.get(\"value\", \"Unknown\") if verdict is not None else \"Unknown\"\n",
    "\n",
    "        # Extract punishment\n",
    "        punishment = trial.find(\".//rs[@type='punishmentDescription']/interp[@type='punishmentCategory']\")\n",
    "        punishment_text = punishment.get(\"value\", \"Unknown\") if punishment is not None else \"Unknown\"\n",
    "\n",
    "        # Extract offence category and subcategory\n",
    "        offence = trial.find(\".//rs[@type='offenceDescription']/interp[@type='offenceCategory']\")\n",
    "        offence_text = offence.get(\"value\", \"Unknown\") if offence is not None else \"Unknown\"\n",
    "        \n",
    "        offence_sub = trial.find(\".//rs[@type='offenceDescription']/interp[@type='offenceSubcategory']\")\n",
    "        offence_subcategory = offence_sub.get(\"value\", \"Unknown\") if offence_sub is not None else \"Unknown\"\n",
    "\n",
    "        # Extract crime date\n",
    "        crime_date = trial.find(\".//rs[@type='crimeDate']\")\n",
    "        crime_date_text = crime_date.text.strip() if crime_date is not None and crime_date.text is not None else \"Unknown\"\n",
    "\n",
    "        # Extract trial text\n",
    "        trial_text = []\n",
    "        for u in trial.findall(\".//u\"):\n",
    "            speaker_role = u.get(\"role\", \"Unknown\")\n",
    "            speaker_text = \" \".join([p.text.strip() for p in u.findall(\".//p\") if p.text])\n",
    "            if speaker_text:\n",
    "                trial_text.append(f\"[{speaker_role}] {speaker_text}\")\n",
    "\n",
    "        full_trial_text = \"\\n\".join(trial_text)\n",
    "\n",
    "        data.append([\n",
    "            trial_id, trial_date, surname, given, \n",
    "            defendant_gender, num_defendants,\n",
    "            victim_surname, victim_given, victim_gender, num_victims,\n",
    "            verdict_text, punishment_text, \n",
    "            offence_text, offence_subcategory,\n",
    "            crime_date_text, full_trial_text\n",
    "        ])\n",
    "\n",
    "columns = [\n",
    "    \"Trial_ID\", \"Date\", \"Defendant_Surname\", \"Defendant_Given\",\n",
    "    \"Defendant_Gender\", \"Num_Defendants\",\n",
    "    \"Victim_Surname\", \"Victim_Given\", \"Victim_Gender\", \"Num_Victims\",\n",
    "    \"Verdict\", \"Punishment\", \n",
    "    \"Offence\", \"Offence_Subcategory\",\n",
    "    \"Crime_Date\", \"Trial_Text\"\n",
    "]\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "print(f\"Parsing complete! {len(df)} rows extracted\")\n",
    "print(f\"\\nMetadata columns: {columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98322bf",
   "metadata": {},
   "source": [
    "## Save Trial Texts to Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a934617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50044 text files to ../dataset/trial_texts/\n"
     ]
    }
   ],
   "source": [
    "output_text_folder = \"../dataset/trial_texts/\"\n",
    "os.makedirs(output_text_folder, exist_ok=True)\n",
    "\n",
    "trial_texts_dict = {}\n",
    "for file in xml_files:\n",
    "    try:\n",
    "        tree = ET.parse(file)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        for trial in root.findall(\".//div1[@type='trialAccount']\"):\n",
    "            trial_id = trial.get(\"id\", \"Unknown\")\n",
    "            trial_text = \" \".join(trial.itertext()).strip()\n",
    "            trial_texts_dict[trial_id] = trial_text\n",
    "            \n",
    "            text_file_path = os.path.join(output_text_folder, f\"{trial_id}.txt\")\n",
    "            with open(text_file_path, \"w\", encoding=\"utf-8\") as txt_file:\n",
    "                txt_file.write(trial_text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "print(f\"Saved {len(trial_texts_dict)} text files to {output_text_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314d9342",
   "metadata": {},
   "source": [
    "## Delete Invalid Trial IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "553980e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid files deleted!\n"
     ]
    }
   ],
   "source": [
    "patterns_to_delete = [\n",
    "    \"a????????-?.txt\",\n",
    "    \"f????????-?.txt\",\n",
    "    \"f????????.txt\",\n",
    "    \"o????????-?.txt\",\n",
    "    \"o????????-??.txt\",\n",
    "    \"s????????-?.txt\"\n",
    "]\n",
    "\n",
    "for pattern in patterns_to_delete:\n",
    "    files_to_delete = glob.glob(os.path.join(output_text_folder, pattern))\n",
    "    for file in files_to_delete:\n",
    "        try:\n",
    "            os.remove(file)\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting {file}: {e}\")\n",
    "\n",
    "print(\"Invalid files deleted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603fbda8",
   "metadata": {},
   "source": [
    "## Filter DataFrame by Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa00be4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering: 100086 rows\n"
     ]
    }
   ],
   "source": [
    "pattern1 = r\"^a\\d{8}-\\d$\"\n",
    "pattern2 = r\"^f\\d{8}-\\d$\"\n",
    "pattern3 = r\"^o\\d{8}-\\d$\"\n",
    "pattern4 = r\"^s\\d{8}-\\d$\"\n",
    "pattern5 = r\"^f\\d{8}$\"\n",
    "pattern6 = r\"^o\\d{8}-\\d{2}$\"\n",
    "\n",
    "df = df[~df[\"Trial_ID\"].str.match(pattern1, na=False)]\n",
    "df = df[~df[\"Trial_ID\"].str.match(pattern2, na=False)]\n",
    "df = df[~df[\"Trial_ID\"].str.match(pattern3, na=False)]\n",
    "df = df[~df[\"Trial_ID\"].str.match(pattern4, na=False)]\n",
    "df = df[~df[\"Trial_ID\"].str.match(pattern5, na=False)]\n",
    "df = df[~df[\"Trial_ID\"].str.match(pattern6, na=False)]\n",
    "\n",
    "print(f\"After filtering: {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9e3868",
   "metadata": {},
   "source": [
    "## Drop Trial_Text Column (temporarily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e95492c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Trial_Text\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eedbcc3",
   "metadata": {},
   "source": [
    "## Clean Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a891c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text files cleaned!\n"
     ]
    }
   ],
   "source": [
    "cleaned_texts_folder = \"../dataset/cleaned_texts/\"\n",
    "os.makedirs(cleaned_texts_folder, exist_ok=True)\n",
    "\n",
    "pos_tag_pattern = r\"\\b(\\w+)_\\w+\\b\"\n",
    "punctuation_pattern = r\"[_,:;\\\"'(){}[\\]<>]+\"\n",
    "\n",
    "for file_name in os.listdir(output_text_folder):\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        input_path = os.path.join(output_text_folder, file_name)\n",
    "        output_path = os.path.join(cleaned_texts_folder, file_name)\n",
    "\n",
    "        with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "        cleaned_text = re.sub(pos_tag_pattern, r\"\\1\", text)\n",
    "        cleaned_text = re.sub(punctuation_pattern, \" \", cleaned_text)\n",
    "        cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text).strip()\n",
    "\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(cleaned_text)\n",
    "\n",
    "final_cleaned_folder = \"../dataset/final_cleaned_texts/\"\n",
    "os.makedirs(final_cleaned_folder, exist_ok=True)\n",
    "\n",
    "pos_tag_pattern = r\"\\b(NNU|NNB)\\b\"\n",
    "punctuation_pattern = r\"\\.\\s+\\.\"\n",
    "\n",
    "for file_name in os.listdir(cleaned_texts_folder):\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        input_path = os.path.join(cleaned_texts_folder, file_name)\n",
    "        output_path = os.path.join(final_cleaned_folder, file_name)\n",
    "\n",
    "        with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "        cleaned_text = re.sub(pos_tag_pattern, \"\", text)\n",
    "        cleaned_text = re.sub(punctuation_pattern, \".\", cleaned_text)\n",
    "        cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text).strip()\n",
    "\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(cleaned_text)\n",
    "\n",
    "print(\"Text files cleaned!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce41547d",
   "metadata": {},
   "source": [
    "## Drop Unnecessary Name Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ab97424",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Victim_Surname\", \"Victim_Given\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c199e9",
   "metadata": {},
   "source": [
    "## Convert Date Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd00a229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date\n",
      "0 1750-01-17\n",
      "1 1750-01-17\n",
      "2 1750-01-17\n",
      "3 1750-01-17\n",
      "4 1750-01-17\n",
      "5 1750-01-17\n",
      "6 1750-01-17\n",
      "7 1750-01-17\n",
      "8 1750-01-17\n",
      "9 1750-01-17\n"
     ]
    }
   ],
   "source": [
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"].astype(str), format=\"%Y%m%d\")\n",
    "print(df[[\"Date\"]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf256b5",
   "metadata": {},
   "source": [
    "## Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "968a8bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dedup: 50043 rows\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset=[\"Trial_ID\"], keep=\"first\")\n",
    "print(f\"After dedup: {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0239ce",
   "metadata": {},
   "source": [
    "## Drop More Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f8ef780",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Defendant_Surname\", \"Defendant_Given\", \"Punishment\", \"Crime_Date\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca62300",
   "metadata": {},
   "source": [
    "## Remove More Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a248023",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=[\"Trial_ID\",\"Date\", \"Verdict\", \"Offence\"], keep=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70fe349",
   "metadata": {},
   "source": [
    "## Add Year Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "541ee9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "df[\"Year\"] = df[\"Date\"].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0e5b03",
   "metadata": {},
   "source": [
    "## Add Trial Text from Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fb9f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_folder = \"../dataset/final_cleaned_texts/\"\n",
    "trial_texts = {}\n",
    "for filename in os.listdir(text_folder):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        trial_id = filename.replace(\".txt\", \"\")\n",
    "        file_path = os.path.join(text_folder, filename)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            trial_texts[trial_id] = f.read().strip()\n",
    "\n",
    "df[\"Trial_Text\"] = df[\"Trial_ID\"].astype(str).map(trial_texts).fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4e673d",
   "metadata": {},
   "source": [
    "## More Deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b16422d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=\"Trial_ID\", keep=\"first\")\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df[\"Year\"] = df[\"Date\"].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877978cc",
   "metadata": {},
   "source": [
    "## Replace Unknown with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28ffc32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(\"unknown\", np.nan, inplace=True)\n",
    "df.replace(\"Unknown\", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee594ad6",
   "metadata": {},
   "source": [
    "## Drop NaN and Filter Verdicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff268538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final rows: 43389\n"
     ]
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df = df[df[\"Verdict\"].isin([\"guilty\", \"notGuilty\"])]\n",
    "print(f\"Final rows: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b700d81f",
   "metadata": {},
   "source": [
    "## Show Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4badb8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verdict distribution:\n",
      "Verdict\n",
      "guilty       31253\n",
      "notGuilty    12136\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Offence distribution:\n",
      "Offence\n",
      "theft            35684\n",
      "violentTheft      2410\n",
      "deception         1436\n",
      "breakingPeace     1204\n",
      "sexual            1069\n",
      "kill              1050\n",
      "royalOffences      234\n",
      "miscellaneous      152\n",
      "damage             150\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Offence Subcategory distribution:\n",
      "Offence_Subcategory\n",
      "grandLarceny                    13539\n",
      "simpleLarceny                    4829\n",
      "theftFromPlace                   4248\n",
      "pocketpicking                    2955\n",
      "burglary                         2290\n",
      "stealingFromMaster               1765\n",
      "other                            1669\n",
      "highwayRobbery                   1469\n",
      "shoplifting                      1197\n",
      "animalTheft                      1035\n",
      "wounding                          953\n",
      "robbery                           941\n",
      "fraud                             865\n",
      "housebreaking                     774\n",
      "murder                            659\n",
      "embezzlement                      499\n",
      "forgery                           489\n",
      "bigamy                            428\n",
      "pettyLarceny                      382\n",
      "manslaughter                      367\n",
      "rape                              364\n",
      "receiving                         303\n",
      "mail                              232\n",
      "coiningOffences                   208\n",
      "assault                           128\n",
      "assaultWithIntent                 100\n",
      "extortion                          89\n",
      "libel                              81\n",
      "arson                              81\n",
      "indecentAssault                    81\n",
      "perjury                            54\n",
      "sodomy                             48\n",
      "kidnapping                         41\n",
      "pervertingJustice                  36\n",
      "keepingABrothel                    33\n",
      "illegalAbortion                    23\n",
      "bankrupcy                          23\n",
      "threateningBehaviour               21\n",
      "riot                               15\n",
      "assaultWithSodomiticalIntent       14\n",
      "taxOffences                        13\n",
      "pettyTreason                       10\n",
      "conspiracy                         10\n",
      "seducingAllegiance                  9\n",
      "gameLawOffence                      8\n",
      "infanticide                         3\n",
      "treason                             2\n",
      "returnFromTransportation            2\n",
      "barratry                            2\n",
      "seditiousLibel                      1\n",
      "concealingABirth                    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Defendant Gender distribution:\n",
      "Defendant_Gender\n",
      "male             32390\n",
      "female           10956\n",
      "indeterminate       43\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Victim Gender distribution:\n",
      "Victim_Gender\n",
      "male             36157\n",
      "female            5958\n",
      "indeterminate     1274\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of Defendants distribution:\n",
      "Num_Defendants\n",
      "1     35637\n",
      "2      6029\n",
      "3      1257\n",
      "4       312\n",
      "5       101\n",
      "6        25\n",
      "7        16\n",
      "8         5\n",
      "9         2\n",
      "11        1\n",
      "13        1\n",
      "16        1\n",
      "19        1\n",
      "35        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of Victims distribution:\n",
      "Num_Victims\n",
      "1     37322\n",
      "2      4463\n",
      "3      1050\n",
      "4       313\n",
      "5       121\n",
      "6        52\n",
      "7        26\n",
      "8        13\n",
      "9         5\n",
      "10       10\n",
      "11        1\n",
      "12        4\n",
      "13        1\n",
      "14        4\n",
      "15        1\n",
      "16        1\n",
      "17        1\n",
      "22        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Year distribution:\n",
      "Year\n",
      "1720    190\n",
      "1721    333\n",
      "1722    297\n",
      "1723    238\n",
      "1724    419\n",
      "       ... \n",
      "1909     52\n",
      "1910    156\n",
      "1911    161\n",
      "1912    162\n",
      "1913    119\n",
      "Name: count, Length: 174, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Verdict distribution:\")\n",
    "print(df[\"Verdict\"].value_counts())\n",
    "print()\n",
    "print(\"Offence distribution:\")\n",
    "print(df[\"Offence\"].value_counts())\n",
    "print()\n",
    "print(\"Offence Subcategory distribution:\")\n",
    "print(df[\"Offence_Subcategory\"].value_counts())\n",
    "print()\n",
    "print(\"Defendant Gender distribution:\")\n",
    "print(df[\"Defendant_Gender\"].value_counts())\n",
    "print()\n",
    "print(\"Victim Gender distribution:\")\n",
    "print(df[\"Victim_Gender\"].value_counts())\n",
    "print()\n",
    "print(\"Number of Defendants distribution:\")\n",
    "print(df[\"Num_Defendants\"].value_counts().sort_index())\n",
    "print()\n",
    "print(\"Number of Victims distribution:\")\n",
    "print(df[\"Num_Victims\"].value_counts().sort_index())\n",
    "print()\n",
    "print(\"Year distribution:\")\n",
    "print(df[\"Year\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636c7998",
   "metadata": {},
   "source": [
    "## Clean Text in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e4e0c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'^[\\W\\d\\s]+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "df['Trial_Text'] = df['Trial_Text'].apply(clean_text)\n",
    "\n",
    "def clean_text1(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'[+*FO]+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df['Trial_Text'] = df['Trial_Text'].apply(clean_text1)\n",
    "\n",
    "def clean_text2(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = re.sub(r'(?<=\\w)\\.(?=[A-Z])', '. ', text)\n",
    "    text = re.sub(r'\\s+([.,!?])', r'\\1', text)\n",
    "    text = re.sub(r\"Prisoner s\", \"Prisoner's\", text)\n",
    "    text = re.sub(r'(\\d+)\\s*d\\s*\\.', r'\\1d.', text)\n",
    "    return text.strip()\n",
    "\n",
    "df['Trial_Text'] = df['Trial_Text'].apply(clean_text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db8976a",
   "metadata": {},
   "source": [
    "## Save Final CSV with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0aa55eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to: ../dataset/OBC_Cleaned_Hybrid.csv\n",
      "\n",
      "Columns in final dataset: ['Trial_ID', 'Date', 'Defendant_Gender', 'Num_Defendants', 'Victim_Gender', 'Num_Victims', 'Verdict', 'Offence', 'Offence_Subcategory', 'Year', 'Trial_Text']\n",
      "\n",
      "Dataset shape: (43389, 11)\n",
      "      Trial_ID       Date Defendant_Gender  Num_Defendants Victim_Gender  \\\n",
      "0  t17500117-1 1750-01-17             male               1          male   \n",
      "1  t17500117-2 1750-01-17             male               2          male   \n",
      "2  t17500117-3 1750-01-17             male               1          male   \n",
      "3  t17500117-4 1750-01-17           female               1          male   \n",
      "4  t17500117-5 1750-01-17           female               2          male   \n",
      "\n",
      "   Num_Victims    Verdict Offence Offence_Subcategory  Year  \\\n",
      "0            1  notGuilty   theft            burglary  1750   \n",
      "1            1     guilty   theft      theftFromPlace  1750   \n",
      "2            1  notGuilty   theft        grandLarceny  1750   \n",
      "3            1     guilty   theft        grandLarceny  1750   \n",
      "4            1  notGuilty   theft        grandLarceny  1750   \n",
      "\n",
      "                                          Trial_Text  \n",
      "0  John Bowen was indicted for that he on the 24t...  \n",
      "1  Nicholas Bond and William Heyden late of ulham...  \n",
      "2  Thomas Biggs was indicted for stealing one pai...  \n",
      "3  Elizabeth Wanless otherwise Newbey spinster wa...  \n",
      "4  Susannah Lowe and Margaret Richards widows wer...  \n"
     ]
    }
   ],
   "source": [
    "output_csv_path = \"../dataset/OBC_Cleaned_Hybrid.csv\"\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "print(f\"File saved to: {output_csv_path}\")\n",
    "print(f\"\\nColumns in final dataset: {list(df.columns)}\")\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skripsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
