{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c90028f",
   "metadata": {},
   "source": [
    "# Old Bailey Corpus Data Parsing - Streamlined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "297feb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cfcbc8",
   "metadata": {},
   "source": [
    "## Parse XML and Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ce1d099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing selesai! 100088 rows extracted\n"
     ]
    }
   ],
   "source": [
    "xml_folder = \"../dataset/OBC2/\"\n",
    "xml_files = glob.glob(os.path.join(xml_folder, \"*.xml\"))\n",
    "data = []\n",
    "\n",
    "for file in xml_files:\n",
    "    tree = ET.parse(file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for trial in root.findall(\".//div1[@type='trialAccount']\"):\n",
    "        trial_id = trial.get(\"id\", \"Unknown\")\n",
    "        trial_date_element = trial.find(\"interp[@type='date']\")\n",
    "        trial_date = trial_date_element.get(\"value\", \"Unknown\") if trial_date_element is not None else \"Unknown\"\n",
    "\n",
    "        defendant = trial.find(\".//persName[@type='defendantName']\")\n",
    "        surname, given = \"Unknown\", \"Unknown\"\n",
    "        if defendant is not None:\n",
    "            surname_element = defendant.find(\"interp[@type='surname']\")\n",
    "            surname = surname_element.get(\"value\", \"Unknown\") if surname_element is not None else \"Unknown\"\n",
    "            given_element = defendant.find(\"interp[@type='given']\")\n",
    "            given = given_element.get(\"value\", \"Unknown\") if given_element is not None else \"Unknown\"\n",
    "\n",
    "        victim = trial.find(\".//persName[@type='victimName']\")\n",
    "        victim_surname, victim_given = \"Unknown\", \"Unknown\"\n",
    "        if victim is not None:\n",
    "            victim_surname_element = victim.find(\"interp[@type='surname']\")\n",
    "            victim_surname = victim_surname_element.get(\"value\", \"Unknown\") if victim_surname_element is not None else \"Unknown\"\n",
    "            victim_given_element = victim.find(\"interp[@type='given']\")\n",
    "            victim_given = victim_given_element.get(\"value\", \"Unknown\") if victim_given_element is not None else \"Unknown\"\n",
    "\n",
    "        verdict = trial.find(\".//rs[@type='verdictDescription']/interp[@type='verdictCategory']\")\n",
    "        verdict_text = verdict.get(\"value\", \"Unknown\") if verdict is not None else \"Unknown\"\n",
    "\n",
    "        punishment = trial.find(\".//rs[@type='punishmentDescription']/interp[@type='punishmentCategory']\")\n",
    "        punishment_text = punishment.get(\"value\", \"Unknown\") if punishment is not None else \"Unknown\"\n",
    "\n",
    "        offence = trial.find(\".//rs[@type='offenceDescription']/interp[@type='offenceCategory']\")\n",
    "        offence_text = offence.get(\"value\", \"Unknown\") if offence is not None else \"Unknown\"\n",
    "\n",
    "        crime_date = trial.find(\".//rs[@type='crimeDate']\")\n",
    "        crime_date_text = crime_date.text.strip() if crime_date is not None and crime_date.text is not None else \"Unknown\"\n",
    "\n",
    "        trial_text = []\n",
    "        for u in trial.findall(\".//u\"):\n",
    "            speaker_role = u.get(\"role\", \"Unknown\")\n",
    "            speaker_text = \" \".join([p.text.strip() for p in u.findall(\".//p\") if p.text])\n",
    "            if speaker_text:\n",
    "                trial_text.append(f\"[{speaker_role}] {speaker_text}\")\n",
    "\n",
    "        full_trial_text = \"\\n\".join(trial_text)\n",
    "\n",
    "        data.append([trial_id, trial_date, surname, given, victim_surname, victim_given, verdict_text, punishment_text, offence_text, crime_date_text, full_trial_text])\n",
    "\n",
    "columns = [\"Trial_ID\", \"Date\", \"Defendant_Surname\", \"Defendant_Given\", \"Victim_Surname\", \"Victim_Given\", \"Verdict\", \"Punishment\", \"Offence\", \"Crime_Date\", \"Trial_Text\"]\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "print(f\"Parsing selesai! {len(df)} rows extracted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71298986",
   "metadata": {},
   "source": [
    "## Save Trial Texts to Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16c587f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 50044 text files to ../dataset/trial_texts/\n"
     ]
    }
   ],
   "source": [
    "output_text_folder = \"../dataset/trial_texts/\"\n",
    "os.makedirs(output_text_folder, exist_ok=True)\n",
    "\n",
    "trial_texts_dict = {}\n",
    "for file in xml_files:\n",
    "    try:\n",
    "        tree = ET.parse(file)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        for trial in root.findall(\".//div1[@type='trialAccount']\"):\n",
    "            trial_id = trial.get(\"id\", \"Unknown\")\n",
    "            trial_text = \" \".join(trial.itertext()).strip()\n",
    "            trial_texts_dict[trial_id] = trial_text\n",
    "            \n",
    "            text_file_path = os.path.join(output_text_folder, f\"{trial_id}.txt\")\n",
    "            with open(text_file_path, \"w\", encoding=\"utf-8\") as txt_file:\n",
    "                txt_file.write(trial_text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "print(f\"Saved {len(trial_texts_dict)} text files to {output_text_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047ed607",
   "metadata": {},
   "source": [
    "## Delete Invalid Trial IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d863220f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid files deleted!\n"
     ]
    }
   ],
   "source": [
    "patterns_to_delete = [\n",
    "    \"a????????-?.txt\",\n",
    "    \"f????????-?.txt\",\n",
    "    \"f????????.txt\",\n",
    "    \"o????????-?.txt\",\n",
    "    \"o????????-??.txt\",\n",
    "    \"s????????-?.txt\"\n",
    "]\n",
    "\n",
    "for pattern in patterns_to_delete:\n",
    "    files_to_delete = glob.glob(os.path.join(output_text_folder, pattern))\n",
    "    for file in files_to_delete:\n",
    "        try:\n",
    "            os.remove(file)\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting {file}: {e}\")\n",
    "\n",
    "print(\"Invalid files deleted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd975b2",
   "metadata": {},
   "source": [
    "## Filter DataFrame by Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f43e383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering: 100086 rows\n"
     ]
    }
   ],
   "source": [
    "pattern1 = r\"^a\\d{8}-\\d$\"\n",
    "pattern2 = r\"^f\\d{8}-\\d$\"\n",
    "pattern3 = r\"^o\\d{8}-\\d$\"\n",
    "pattern4 = r\"^s\\d{8}-\\d$\"\n",
    "pattern5 = r\"^f\\d{8}$\"\n",
    "pattern6 = r\"^o\\d{8}-\\d{2}$\"\n",
    "\n",
    "df = df[~df[\"Trial_ID\"].str.match(pattern1, na=False)]\n",
    "df = df[~df[\"Trial_ID\"].str.match(pattern2, na=False)]\n",
    "df = df[~df[\"Trial_ID\"].str.match(pattern3, na=False)]\n",
    "df = df[~df[\"Trial_ID\"].str.match(pattern4, na=False)]\n",
    "df = df[~df[\"Trial_ID\"].str.match(pattern5, na=False)]\n",
    "df = df[~df[\"Trial_ID\"].str.match(pattern6, na=False)]\n",
    "\n",
    "print(f\"After filtering: {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2df3159",
   "metadata": {},
   "source": [
    "## Drop Trial_Text Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07c17b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Trial_Text\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69e0cbc",
   "metadata": {},
   "source": [
    "## Clean Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32b1131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text files cleaned!\n"
     ]
    }
   ],
   "source": [
    "cleaned_texts_folder = \"../dataset/cleaned_texts/\"\n",
    "os.makedirs(cleaned_texts_folder, exist_ok=True)\n",
    "\n",
    "pos_tag_pattern = r\"\\b(\\w+)_\\w+\\b\"\n",
    "punctuation_pattern = r\"[_,:;\\\"'(){}[\\]<>]+\"\n",
    "\n",
    "for file_name in os.listdir(output_text_folder):\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        input_path = os.path.join(output_text_folder, file_name)\n",
    "        output_path = os.path.join(cleaned_texts_folder, file_name)\n",
    "\n",
    "        with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "        cleaned_text = re.sub(pos_tag_pattern, r\"\\1\", text)\n",
    "        cleaned_text = re.sub(punctuation_pattern, \" \", cleaned_text)\n",
    "        cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text).strip()\n",
    "\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(cleaned_text)\n",
    "\n",
    "final_cleaned_folder = \"../dataset/final_cleaned_texts/\"\n",
    "os.makedirs(final_cleaned_folder, exist_ok=True)\n",
    "\n",
    "pos_tag_pattern = r\"\\b(NNU|NNB)\\b\"\n",
    "punctuation_pattern = r\"\\.\\s+\\.\"\n",
    "\n",
    "for file_name in os.listdir(cleaned_texts_folder):\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        input_path = os.path.join(cleaned_texts_folder, file_name)\n",
    "        output_path = os.path.join(final_cleaned_folder, file_name)\n",
    "\n",
    "        with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "        cleaned_text = re.sub(pos_tag_pattern, \"\", text)\n",
    "        cleaned_text = re.sub(punctuation_pattern, \".\", cleaned_text)\n",
    "        cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text).strip()\n",
    "\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(cleaned_text)\n",
    "\n",
    "print(\"Text files cleaned!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3f5c89",
   "metadata": {},
   "source": [
    "## Drop Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be0966c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Victim_Surname\", \"Victim_Given\", \"Witness_Name\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c7401d",
   "metadata": {},
   "source": [
    "## Convert Date Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "269edd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date\n",
      "0 1750-01-17\n",
      "1 1750-01-17\n",
      "2 1750-01-17\n",
      "3 1750-01-17\n",
      "4 1750-01-17\n",
      "5 1750-01-17\n",
      "6 1750-01-17\n",
      "7 1750-01-17\n",
      "8 1750-01-17\n",
      "9 1750-01-17\n"
     ]
    }
   ],
   "source": [
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"].astype(str), format=\"%Y%m%d\")\n",
    "print(df[[\"Date\"]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45e569b",
   "metadata": {},
   "source": [
    "## Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0817f835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dedup: 50043 rows\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset=[\"Trial_ID\"], keep=\"first\")\n",
    "print(f\"After dedup: {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de144593",
   "metadata": {},
   "source": [
    "## Drop More Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35c49d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Defendant_Surname\", \"Defendant_Given\", \"Punishment\", \"Crime_Date\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1878df6",
   "metadata": {},
   "source": [
    "## Remove More Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96cae063",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=[\"Trial_ID\",\"Date\", \"Verdict\", \"Offence\"], keep=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f083ced",
   "metadata": {},
   "source": [
    "## Add Year Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d1b6b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "df[\"Year\"] = df[\"Date\"].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105d6405",
   "metadata": {},
   "source": [
    "## Add Trial Text from Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73587b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_folder = \"../dataset/final_cleaned_texts/\"\n",
    "trial_texts = {}\n",
    "for filename in os.listdir(text_folder):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        trial_id = filename.replace(\".txt\", \"\")\n",
    "        file_path = os.path.join(text_folder, filename)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            trial_texts[trial_id] = f.read().strip()\n",
    "\n",
    "df[\"Trial_Text\"] = df[\"Trial_ID\"].astype(str).map(trial_texts).fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72472e44",
   "metadata": {},
   "source": [
    "## More Deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "599bd682",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=\"Trial_ID\", keep=\"first\")\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df[\"Year\"] = df[\"Date\"].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8133ad80",
   "metadata": {},
   "source": [
    "## Replace Unknown with NaN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bfc3265",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(\"unknown\", np.nan, inplace=True)\n",
    "df.replace(\"Unknown\", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b0b8cb",
   "metadata": {},
   "source": [
    "## Drop NaN and Filter Verdicts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab5aacf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final rows: 49365\n"
     ]
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df = df[df[\"Verdict\"].isin([\"guilty\", \"notGuilty\"])]\n",
    "print(f\"Final rows: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151a6e24",
   "metadata": {},
   "source": [
    "## Show Stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f540c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verdict\n",
      "guilty       35487\n",
      "notGuilty    13878\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Offence\n",
      "theft            37033\n",
      "deception         2956\n",
      "violentTheft      2433\n",
      "royalOffences     2135\n",
      "sexual            1434\n",
      "breakingPeace     1319\n",
      "kill              1205\n",
      "miscellaneous      654\n",
      "damage             196\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Year\n",
      "1720    210\n",
      "1721    370\n",
      "1722    320\n",
      "1723    260\n",
      "1724    449\n",
      "       ... \n",
      "1909     63\n",
      "1910    206\n",
      "1911    204\n",
      "1912    189\n",
      "1913    151\n",
      "Name: count, Length: 174, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Verdict\"].value_counts())\n",
    "print()\n",
    "print(df[\"Offence\"].value_counts())\n",
    "print()\n",
    "print(df[\"Year\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4822b4",
   "metadata": {},
   "source": [
    "## Clean Text in DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4bdc246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'^[\\W\\d\\s]+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "df['Trial_Text'] = df['Trial_Text'].apply(clean_text)\n",
    "\n",
    "def clean_text1(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'[+*FO]+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df['Trial_Text'] = df['Trial_Text'].apply(clean_text1)\n",
    "\n",
    "def clean_text2(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = re.sub(r'(?<=\\w)\\.(?=[A-Z])', '. ', text)\n",
    "    text = re.sub(r'\\s+([.,!?])', r'\\1', text)\n",
    "    text = re.sub(r\"Prisoner s\", \"Prisoner's\", text)\n",
    "    text = re.sub(r'(\\d+)\\s*d\\s*\\.', r'\\1d.', text)\n",
    "    return text.strip()\n",
    "\n",
    "df['Trial_Text'] = df['Trial_Text'].apply(clean_text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa9bf1e",
   "metadata": {},
   "source": [
    "## Save Final CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f32ed6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ File disimpan di: ../dataset/OBC_Cleaned.csv\n",
      "      Trial_ID       Date    Verdict Offence  Year  \\\n",
      "0  t17500117-1 1750-01-17  notGuilty   theft  1750   \n",
      "1  t17500117-2 1750-01-17     guilty   theft  1750   \n",
      "2  t17500117-3 1750-01-17  notGuilty   theft  1750   \n",
      "3  t17500117-4 1750-01-17     guilty   theft  1750   \n",
      "4  t17500117-5 1750-01-17  notGuilty   theft  1750   \n",
      "\n",
      "                                          Trial_Text  \n",
      "0  John Bowen was indicted for that he on the 24t...  \n",
      "1  Nicholas Bond and William Heyden late of ulham...  \n",
      "2  Thomas Biggs was indicted for stealing one pai...  \n",
      "3  Elizabeth Wanless otherwise Newbey spinster wa...  \n",
      "4  Susannah Lowe and Margaret Richards widows wer...  \n"
     ]
    }
   ],
   "source": [
    "output_csv_path = \"../dataset/OBC_Cleaned.csv\"\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "print(f\"File disimpan di: {output_csv_path}\")\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skripsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
