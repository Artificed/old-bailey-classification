{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9d73b29",
   "metadata": {},
   "source": [
    "## Step 1: Count XML Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3ded572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of XML files: 1274\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = \"../dataset/OBC2\"\n",
    "file_count = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
    "\n",
    "print(f\"Number of XML files: {file_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d53b13",
   "metadata": {},
   "source": [
    "## Step 2: Parse XML Files to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3a227b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing 1274 XML files...\n",
      "\n",
      "Parsing completed! Initial dataset shape: (100088, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trial_ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Defendant_Surname</th>\n",
       "      <th>Defendant_Given</th>\n",
       "      <th>Victim_Surname</th>\n",
       "      <th>Victim_Given</th>\n",
       "      <th>Verdict</th>\n",
       "      <th>Punishment</th>\n",
       "      <th>Offence</th>\n",
       "      <th>Crime_Date</th>\n",
       "      <th>Trial_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t17500117-1</td>\n",
       "      <td>17500117</td>\n",
       "      <td>Bowen</td>\n",
       "      <td>John</td>\n",
       "      <td>Gwinn</td>\n",
       "      <td>William</td>\n",
       "      <td>notGuilty</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>theft</td>\n",
       "      <td>24th_MD of_IO February_NPM1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t17500117-2</td>\n",
       "      <td>17500117</td>\n",
       "      <td>Bond</td>\n",
       "      <td>Nicholas</td>\n",
       "      <td>Page</td>\n",
       "      <td>Henry</td>\n",
       "      <td>guilty</td>\n",
       "      <td>transport</td>\n",
       "      <td>theft</td>\n",
       "      <td>Jan._NPM1 9_MC</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t17500117-3</td>\n",
       "      <td>17500117</td>\n",
       "      <td>Biggs</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>Gordon</td>\n",
       "      <td>William</td>\n",
       "      <td>notGuilty</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>theft</td>\n",
       "      <td>Unknown</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t17500117-4</td>\n",
       "      <td>17500117</td>\n",
       "      <td>Wanless</td>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>Broadhurst</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>guilty</td>\n",
       "      <td>transport</td>\n",
       "      <td>theft</td>\n",
       "      <td>October_NPM1 25_MC</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t17500117-5</td>\n",
       "      <td>17500117</td>\n",
       "      <td>Lowe</td>\n",
       "      <td>Susannah</td>\n",
       "      <td>Wolse</td>\n",
       "      <td>Ezekiel</td>\n",
       "      <td>notGuilty</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>theft</td>\n",
       "      <td>Dec._NPM1 20_MC</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Trial_ID      Date Defendant_Surname Defendant_Given Victim_Surname  \\\n",
       "0  t17500117-1  17500117             Bowen            John          Gwinn   \n",
       "1  t17500117-2  17500117              Bond        Nicholas           Page   \n",
       "2  t17500117-3  17500117             Biggs          Thomas         Gordon   \n",
       "3  t17500117-4  17500117           Wanless       Elizabeth     Broadhurst   \n",
       "4  t17500117-5  17500117              Lowe        Susannah          Wolse   \n",
       "\n",
       "  Victim_Given    Verdict Punishment Offence                   Crime_Date  \\\n",
       "0      William  notGuilty    Unknown   theft  24th_MD of_IO February_NPM1   \n",
       "1        Henry     guilty  transport   theft               Jan._NPM1 9_MC   \n",
       "2      William  notGuilty    Unknown   theft                      Unknown   \n",
       "3       Thomas     guilty  transport   theft           October_NPM1 25_MC   \n",
       "4      Ezekiel  notGuilty    Unknown   theft              Dec._NPM1 20_MC   \n",
       "\n",
       "  Trial_Text  \n",
       "0             \n",
       "1             \n",
       "2             \n",
       "3             \n",
       "4             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "xml_folder = \"../dataset/OBC2/\"\n",
    "xml_files = glob.glob(os.path.join(xml_folder, \"*.xml\"))\n",
    "data = []\n",
    "\n",
    "print(f\"Parsing {len(xml_files)} XML files...\")\n",
    "\n",
    "for file in xml_files:\n",
    "    tree = ET.parse(file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for trial in root.findall(\".//div1[@type='trialAccount']\"):\n",
    "        trial_id = trial.get(\"id\", \"Unknown\")\n",
    "        trial_date_element = trial.find(\"interp[@type='date']\")\n",
    "        trial_date = trial_date_element.get(\"value\", \"Unknown\") if trial_date_element is not None else \"Unknown\"\n",
    "\n",
    "        defendant = trial.find(\".//persName[@type='defendantName']\")\n",
    "        surname, given = \"Unknown\", \"Unknown\"\n",
    "        if defendant is not None:\n",
    "            surname_element = defendant.find(\"interp[@type='surname']\")\n",
    "            surname = surname_element.get(\"value\", \"Unknown\") if surname_element is not None else \"Unknown\"\n",
    "            given_element = defendant.find(\"interp[@type='given']\")\n",
    "            given = given_element.get(\"value\", \"Unknown\") if given_element is not None else \"Unknown\"\n",
    "\n",
    "        victim = trial.find(\".//persName[@type='victimName']\")\n",
    "        victim_surname, victim_given = \"Unknown\", \"Unknown\"\n",
    "        if victim is not None:\n",
    "            victim_surname_element = victim.find(\"interp[@type='surname']\")\n",
    "            victim_surname = victim_surname_element.get(\"value\", \"Unknown\") if victim_surname_element is not None else \"Unknown\"\n",
    "            victim_given_element = victim.find(\"interp[@type='given']\")\n",
    "            victim_given = victim_given_element.get(\"value\", \"Unknown\") if victim_given_element is not None else \"Unknown\"\n",
    "\n",
    "        verdict = trial.find(\".//rs[@type='verdictDescription']/interp[@type='verdictCategory']\")\n",
    "        verdict_text = verdict.get(\"value\", \"Unknown\") if verdict is not None else \"Unknown\"\n",
    "\n",
    "        punishment = trial.find(\".//rs[@type='punishmentDescription']/interp[@type='punishmentCategory']\")\n",
    "        punishment_text = punishment.get(\"value\", \"Unknown\") if punishment is not None else \"Unknown\"\n",
    "\n",
    "        offence = trial.find(\".//rs[@type='offenceDescription']/interp[@type='offenceCategory']\")\n",
    "        offence_text = offence.get(\"value\", \"Unknown\") if offence is not None else \"Unknown\"\n",
    "\n",
    "        crime_date = trial.find(\".//rs[@type='crimeDate']\")\n",
    "        crime_date_text = crime_date.text.strip() if crime_date is not None and crime_date.text is not None else \"Unknown\"\n",
    "\n",
    "        trial_text = []\n",
    "        for u in trial.findall(\".//u\"):\n",
    "            speaker_role = u.get(\"role\", \"Unknown\")\n",
    "            speaker_text = \" \".join([p.text.strip() for p in u.findall(\".//p\") if p.text])\n",
    "            if speaker_text:\n",
    "                trial_text.append(f\"[{speaker_role}] {speaker_text}\")\n",
    "\n",
    "        full_trial_text = \"\\n\".join(trial_text)\n",
    "\n",
    "        data.append([trial_id, trial_date, surname, given, victim_surname, victim_given, verdict_text, punishment_text, offence_text, crime_date_text, full_trial_text])\n",
    "\n",
    "columns = [\"Trial_ID\", \"Date\", \"Defendant_Surname\", \"Defendant_Given\", \"Victim_Surname\", \"Victim_Given\", \"Verdict\", \"Punishment\", \"Offence\", \"Crime_Date\", \"Trial_Text\"]\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "print(f\"\\nParsing completed! Initial dataset shape: {df.shape}\")\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501b4e73",
   "metadata": {},
   "source": [
    "## Step 3: Extract and Clean Trial Texts to Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "301f0ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 100088 trial texts to ../dataset/trial_texts/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "xml_folder = \"../dataset/OBC2/\"\n",
    "output_text_folder = \"../dataset/trial_texts/\"\n",
    "os.makedirs(output_text_folder, exist_ok=True)\n",
    "xml_files = glob.glob(os.path.join(xml_folder, \"*.xml\"))\n",
    "\n",
    "trial_count = 0\n",
    "for file in xml_files:\n",
    "    try:\n",
    "        tree = ET.parse(file)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        for trial in root.findall(\".//div1[@type='trialAccount']\"):\n",
    "            trial_id = trial.get(\"id\", \"Unknown\")\n",
    "            trial_text = \" \".join(trial.itertext()).strip()\n",
    "\n",
    "            text_file_path = os.path.join(output_text_folder, f\"{trial_id}.txt\")\n",
    "            with open(text_file_path, \"w\", encoding=\"utf-8\") as txt_file:\n",
    "                txt_file.write(trial_text)\n",
    "            trial_count += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "print(f\"Extracted {trial_count} trial texts to {output_text_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4fb9ab",
   "metadata": {},
   "source": [
    "### Remove Invalid Trial ID Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b83318db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 1 files with invalid patterns\n",
      "Remaining trial text files: 50043\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "output_text_folder = \"../dataset/trial_texts/\"\n",
    "\n",
    "patterns = [\n",
    "    \"a????????-?.txt\",\n",
    "    \"f????????-?.txt\",\n",
    "    \"f????????.txt\",\n",
    "    \"o????????-?.txt\",\n",
    "    \"o????????-??.txt\",\n",
    "    \"s????????-?.txt\"\n",
    "]\n",
    "\n",
    "total_deleted = 0\n",
    "for pattern in patterns:\n",
    "    full_pattern = os.path.join(output_text_folder, pattern)\n",
    "    files_to_delete = glob.glob(full_pattern)\n",
    "    \n",
    "    for file in files_to_delete:\n",
    "        try:\n",
    "            os.remove(file)\n",
    "            total_deleted += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting {file}: {e}\")\n",
    "\n",
    "remaining_files = len([f for f in os.listdir(output_text_folder) if os.path.isfile(os.path.join(output_text_folder, f))])\n",
    "print(f\"Deleted {total_deleted} files with invalid patterns\")\n",
    "print(f\"Remaining trial text files: {remaining_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e52f90b",
   "metadata": {},
   "source": [
    "## Step 4: DataFrame Cleaning Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80b632b",
   "metadata": {},
   "source": [
    "### 4.1: Remove Invalid Trial_ID Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1145b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DataFrame cleaning pipeline...\n",
      "\n",
      "Initial shape: (100088, 11)\n",
      "\n",
      "Removing invalid Trial_ID patterns...\n",
      "Shape after removing invalid IDs: (100086, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Starting DataFrame cleaning pipeline...\\n\")\n",
    "print(f\"Initial shape: {df.shape}\")\n",
    "\n",
    "print(\"\\nRemoving invalid Trial_ID patterns...\")\n",
    "patterns = [r\"^a\\d{8}-\\d$\", r\"^f\\d{8}-\\d$\", r\"^o\\d{8}-\\d$\", r\"^s\\d{8}-\\d$\", r\"^f\\d{8}$\", r\"^o\\d{8}-\\d{2}$\"]\n",
    "for pattern in patterns:\n",
    "    df = df[~df[\"Trial_ID\"].str.match(pattern, na=False)]\n",
    "print(f\"Shape after removing invalid IDs: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba518fb7",
   "metadata": {},
   "source": [
    "### 4.2: Drop Trial_Text Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ef77f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping Trial_Text column...\n",
      "Columns: ['Trial_ID', 'Date', 'Defendant_Surname', 'Defendant_Given', 'Victim_Surname', 'Victim_Given', 'Verdict', 'Punishment', 'Offence', 'Crime_Date']\n"
     ]
    }
   ],
   "source": [
    "print(\"Dropping Trial_Text column...\")\n",
    "df = df.drop(columns=[\"Trial_Text\"], errors=\"ignore\")\n",
    "print(f\"Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c15681",
   "metadata": {},
   "source": [
    "### 4.3: Drop Unnecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f2a591b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping unnecessary columns...\n",
      "Columns: ['Trial_ID', 'Date', 'Defendant_Surname', 'Defendant_Given', 'Verdict', 'Punishment', 'Offence', 'Crime_Date']\n"
     ]
    }
   ],
   "source": [
    "print(\"Dropping unnecessary columns...\")\n",
    "df = df.drop(columns=[\"Victim_Surname\", \"Victim_Given\", \"Witness_Name\"], errors=\"ignore\")\n",
    "print(f\"Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bb0aa0",
   "metadata": {},
   "source": [
    "### 4.4: Convert Date to Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb3254ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Date to datetime format...\n",
      "Date sample: [Timestamp('1750-01-17 00:00:00'), Timestamp('1750-01-17 00:00:00'), Timestamp('1750-01-17 00:00:00')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Converting Date to datetime format...\")\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"].astype(str), format=\"%Y%m%d\")\n",
    "print(f\"Date sample: {df['Date'].head(3).tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469e5790",
   "metadata": {},
   "source": [
    "### 4.5: Remove Duplicate Trial_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "143c3406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for duplicates...\n",
      "Found 100086 duplicate rows\n",
      "Shape after removing duplicates: (50043, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking for duplicates...\")\n",
    "duplicates = df[df.duplicated(subset=[\"Trial_ID\"], keep=False)]\n",
    "print(f\"Found {len(duplicates)} duplicate rows\")\n",
    "df = df.drop_duplicates(subset=[\"Trial_ID\"], keep=\"first\")\n",
    "print(f\"Shape after removing duplicates: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e5b50f",
   "metadata": {},
   "source": [
    "### 4.6: Drop Defendant and Crime Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3655741e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping defendant and crime details...\n",
      "Columns: ['Trial_ID', 'Date', 'Verdict', 'Offence']\n"
     ]
    }
   ],
   "source": [
    "print(\"Dropping defendant and crime details...\")\n",
    "df = df.drop(columns=[\"Defendant_Surname\", \"Defendant_Given\", \"Punishment\", \"Crime_Date\"], errors=\"ignore\")\n",
    "print(f\"Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca5329d",
   "metadata": {},
   "source": [
    "### 4.7: Remove Multi-Column Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f97d1334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing duplicates by Trial_ID, Date, Verdict, Offence...\n",
      "Shape: (50043, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Removing duplicates by Trial_ID, Date, Verdict, Offence...\")\n",
    "df = df.drop_duplicates(subset=[\"Trial_ID\", \"Date\", \"Verdict\", \"Offence\"], keep=\"first\")\n",
    "print(f\"Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7b27eb",
   "metadata": {},
   "source": [
    "### 4.8: Extract Year from Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a3bc808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Year from Date...\n",
      "Year range: 1720 - 1913\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting Year from Date...\")\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "df[\"Year\"] = df[\"Date\"].dt.year\n",
    "print(f\"Year range: {df['Year'].min()} - {df['Year'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e870229e",
   "metadata": {},
   "source": [
    "### 4.9: Load Cleaned Trial Texts from Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc15f89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and cleaning trial texts from files...\n",
      "Trial texts loaded and cleaned: 50043\n",
      "Rows with text: 50042\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "print(\"Loading and cleaning trial texts from files...\")\n",
    "text_folder = \"../dataset/trial_texts/\"\n",
    "\n",
    "def apply_first_pass(text):\n",
    "    text = re.sub(r\"\\b(\\w+)_\\w+\\b\", r\"\\1\", text)\n",
    "    text = re.sub(r\"[_,:;\\\"'(){}[\\]<>]+\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def apply_second_pass(text):\n",
    "    text = re.sub(r\"\\b(NNU|NNB)\\b\", \"\", text)\n",
    "    text = re.sub(r\"\\.\\s+\\.\", \".\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "trial_texts = {}\n",
    "for filename in os.listdir(text_folder):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        trial_id = filename.replace(\".txt\", \"\")\n",
    "        file_path = os.path.join(text_folder, filename)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read().strip()\n",
    "            text = apply_first_pass(text)\n",
    "            text = apply_second_pass(text)\n",
    "            trial_texts[trial_id] = text\n",
    "\n",
    "df[\"Trial_Text\"] = df[\"Trial_ID\"].astype(str).map(trial_texts).fillna(\"\")\n",
    "print(f\"Trial texts loaded and cleaned: {len(trial_texts)}\")\n",
    "print(f\"Rows with text: {(df['Trial_Text'] != '').sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbabbce1",
   "metadata": {},
   "source": [
    "### 4.10: Final Duplicate Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64bbcd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final duplicate removal...\n",
      "Shape: (50043, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Final duplicate removal...\")\n",
    "df = df.drop_duplicates(subset=\"Trial_ID\", keep=\"first\")\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df[\"Year\"] = df[\"Date\"].dt.year\n",
    "print(f\"Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c180c3",
   "metadata": {},
   "source": [
    "### 4.11: Replace Unknown Values with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56341c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing 'unknown' values with NaN...\n",
      "Missing values per column:\n",
      "Trial_ID        0\n",
      "Date            0\n",
      "Verdict       561\n",
      "Offence        27\n",
      "Year            0\n",
      "Trial_Text      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Replacing 'unknown' values with NaN...\")\n",
    "df.replace(\"unknown\", np.nan, inplace=True)\n",
    "df.replace(\"Unknown\", np.nan, inplace=True)\n",
    "print(f\"Missing values per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364b8e66",
   "metadata": {},
   "source": [
    "### 4.12: Filter to Valid Verdicts Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e77dc0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping NaN rows and filtering verdicts...\n",
      "Shape after filtering: (49365, 6)\n",
      "\n",
      "Verdict distribution:\n",
      "Verdict\n",
      "guilty       35487\n",
      "notGuilty    13878\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Offence distribution:\n",
      "Offence\n",
      "theft            37033\n",
      "deception         2956\n",
      "violentTheft      2433\n",
      "royalOffences     2135\n",
      "sexual            1434\n",
      "breakingPeace     1319\n",
      "kill              1205\n",
      "miscellaneous      654\n",
      "damage             196\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "DataFrame cleaning complete!\n",
      "Final shape: (49365, 6)\n",
      "Columns: ['Trial_ID', 'Date', 'Verdict', 'Offence', 'Year', 'Trial_Text']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trial_ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Verdict</th>\n",
       "      <th>Offence</th>\n",
       "      <th>Year</th>\n",
       "      <th>Trial_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t17500117-1</td>\n",
       "      <td>1750-01-17</td>\n",
       "      <td>notGuilty</td>\n",
       "      <td>theft</td>\n",
       "      <td>1750</td>\n",
       "      <td>109. John Bowen was indicted for that he on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t17500117-2</td>\n",
       "      <td>1750-01-17</td>\n",
       "      <td>guilty</td>\n",
       "      <td>theft</td>\n",
       "      <td>1750</td>\n",
       "      <td>110 111. Nicholas Bond and William Heyden late...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t17500117-3</td>\n",
       "      <td>1750-01-17</td>\n",
       "      <td>notGuilty</td>\n",
       "      <td>theft</td>\n",
       "      <td>1750</td>\n",
       "      <td>112. Thomas Biggs was indicted for stealing on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t17500117-4</td>\n",
       "      <td>1750-01-17</td>\n",
       "      <td>guilty</td>\n",
       "      <td>theft</td>\n",
       "      <td>1750</td>\n",
       "      <td>113. Elizabeth Wanless otherwise Newbey spinst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t17500117-5</td>\n",
       "      <td>1750-01-17</td>\n",
       "      <td>notGuilty</td>\n",
       "      <td>theft</td>\n",
       "      <td>1750</td>\n",
       "      <td>114 115. Susannah Lowe and Margaret Richards w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Trial_ID       Date    Verdict Offence  Year  \\\n",
       "0  t17500117-1 1750-01-17  notGuilty   theft  1750   \n",
       "1  t17500117-2 1750-01-17     guilty   theft  1750   \n",
       "2  t17500117-3 1750-01-17  notGuilty   theft  1750   \n",
       "3  t17500117-4 1750-01-17     guilty   theft  1750   \n",
       "4  t17500117-5 1750-01-17  notGuilty   theft  1750   \n",
       "\n",
       "                                          Trial_Text  \n",
       "0  109. John Bowen was indicted for that he on th...  \n",
       "1  110 111. Nicholas Bond and William Heyden late...  \n",
       "2  112. Thomas Biggs was indicted for stealing on...  \n",
       "3  113. Elizabeth Wanless otherwise Newbey spinst...  \n",
       "4  114 115. Susannah Lowe and Margaret Richards w...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Dropping NaN rows and filtering verdicts...\")\n",
    "df.dropna(inplace=True)\n",
    "df = df[df[\"Verdict\"].isin([\"guilty\", \"notGuilty\"])]\n",
    "print(f\"Shape after filtering: {df.shape}\")\n",
    "print(f\"\\nVerdict distribution:\")\n",
    "print(df[\"Verdict\"].value_counts())\n",
    "print(f\"\\nOffence distribution:\")\n",
    "print(df[\"Offence\"].value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DataFrame cleaning complete!\")\n",
    "print(f\"Final shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d8be06",
   "metadata": {},
   "source": [
    "## Step 5: Text Cleaning Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad1919f",
   "metadata": {},
   "source": [
    "### 5.1: Remove Leading Non-Alphanumeric Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b9c7bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/3] Removing leading non-alphanumeric characters...\n",
      "Sample: John Bowen was indicted for that he on the 24th of February between the hour of twelve and one in th...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'^[\\W\\d\\s]+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "print(\"[1/3] Removing leading non-alphanumeric characters...\")\n",
    "df['Trial_Text'] = df['Trial_Text'].apply(clean_text)\n",
    "print(f\"Sample: {df['Trial_Text'].iloc[0][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb8f5e2",
   "metadata": {},
   "source": [
    "### 5.2: Remove Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8a0229e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/3] Removing special characters (+*FO)...\n",
      "Sample: John Bowen was indicted for that he on the 24th of ebruary between the hour of twelve and one in the...\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text1(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'[+*FO]+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "print(\"[2/3] Removing special characters (+*FO)...\")\n",
    "df['Trial_Text'] = df['Trial_Text'].apply(clean_text1)\n",
    "print(f\"Sample: {df['Trial_Text'].iloc[0][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e025a94",
   "metadata": {},
   "source": [
    "### 5.3: Fix Spacing and Apostrophes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6fb8e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/3] Fixing spacing and apostrophes...\n",
      "Sample: John Bowen was indicted for that he on the 24th of ebruary between the hour of twelve and one in the...\n",
      "\n",
      "Text cleaning complete!\n",
      "Average text length: 3028 characters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def clean_text2(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = re.sub(r'(?<=\\w)\\.(?=[A-Z])', '. ', text)\n",
    "    text = re.sub(r'\\s+([.,!?])', r'\\1', text)\n",
    "    text = re.sub(r\"Prisoner s\", \"Prisoner's\", text)\n",
    "    text = re.sub(r'(\\d+)\\s*d\\s*\\.', r'\\1d.', text)\n",
    "    return text.strip()\n",
    "\n",
    "print(\"[3/3] Fixing spacing and apostrophes...\")\n",
    "df['Trial_Text'] = df['Trial_Text'].apply(clean_text2)\n",
    "print(f\"Sample: {df['Trial_Text'].iloc[0][:100]}...\")\n",
    "\n",
    "print(\"\\nText cleaning complete!\")\n",
    "print(f\"Average text length: {df['Trial_Text'].str.len().mean():.0f} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fb7fc7",
   "metadata": {},
   "source": [
    "## Step 6: NLTK Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eafec6",
   "metadata": {},
   "source": [
    "### 6.1: Download and Setup NLTK Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19e6feb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NLTK resources...\n",
      "  punkt: downloading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to ./nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package punkt_tab to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  punkt_tab: downloading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package wordnet to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  wordnet: downloading...\n",
      "  omw-1.4: downloading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  averaged_perceptron_tagger_eng: downloading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  stopwords: downloading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
      "[nltk_data] Downloading package stopwords to ./nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "\n",
    "nltk_data_dir = \"./nltk_data\"\n",
    "nltk.data.path.append(nltk_data_dir)\n",
    "os.makedirs(nltk_data_dir, exist_ok=True)\n",
    "\n",
    "nltk_resources = [\n",
    "    \"punkt\",\n",
    "    \"punkt_tab\",\n",
    "    \"wordnet\",\n",
    "    \"omw-1.4\",\n",
    "    \"averaged_perceptron_tagger_eng\",\n",
    "    \"stopwords\"\n",
    "]\n",
    "\n",
    "print(\"Downloading NLTK resources...\")\n",
    "for resource in nltk_resources:\n",
    "    try:\n",
    "        nltk.data.find(resource)\n",
    "        print(f\"  {resource}: already present\")\n",
    "    except LookupError:\n",
    "        print(f\"  {resource}: downloading...\")\n",
    "        nltk.download(resource, download_dir=nltk_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013ccaea",
   "metadata": {},
   "source": [
    "### 6.2: Setup NLTK Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aaf2a706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords loaded: 198\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(f\"Stopwords loaded: {len(stop_words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8212064",
   "metadata": {},
   "source": [
    "### 6.3: Define NLTK Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df528c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK cleaning function defined\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith(\"J\"):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith(\"V\"):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith(\"N\"):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith(\"R\"):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def clean_text_nltk(text):\n",
    "    try:\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "        text = re.sub(r\"^\\s*[TM]\\.\\s*\", \"\", text)\n",
    "        text = re.sub(r\"[^a-zA-Z\\s]\", \" \", text)\n",
    "        text = re.sub(r\"\\b\\w{1,2}\\b\", \" \", text)\n",
    "\n",
    "        sentences = sent_tokenize(text)\n",
    "        cleaned_sentences = []\n",
    "\n",
    "        for sentence in sentences:\n",
    "            words = word_tokenize(sentence.lower())\n",
    "            words = [word for word in words if word not in stop_words]\n",
    "            tagged_words = pos_tag(words)\n",
    "            lemmatized_words = [\n",
    "                lemmatizer.lemmatize(word, get_wordnet_pos(tag))\n",
    "                for word, tag in tagged_words\n",
    "            ]\n",
    "            cleaned_sentences.append(\" \".join(lemmatized_words))\n",
    "\n",
    "        return \" \".join(cleaned_sentences)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to process text: {e}\")\n",
    "        return text\n",
    "\n",
    "print(\"NLTK cleaning function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b6af96",
   "metadata": {},
   "source": [
    "### 6.4: Apply NLTK Processing to All Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ac31dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying NLTK processing (this may take a while)...\n",
      "Processing 49365 trials...\n",
      "\n",
      "NLTK processing complete!\n",
      "Sample processed text: john bowen indict ebruary hour twelve one morning dwelling house william gwinn break enter steal thence twenty yard linnen cheque thirty cotton handkerchief seventy nine yard stripe cotton six pair wo...\n",
      "\n",
      "Average processed text length: 1606 characters\n"
     ]
    }
   ],
   "source": [
    "print(\"Applying NLTK processing (this may take a while)...\")\n",
    "print(f\"Processing {len(df)} trials...\")\n",
    "\n",
    "df[\"Trial_Text\"] = df[\"Trial_Text\"].astype(str).apply(clean_text_nltk)\n",
    "\n",
    "print(\"\\nNLTK processing complete!\")\n",
    "print(f\"Sample processed text: {df['Trial_Text'].iloc[0][:200]}...\")\n",
    "print(f\"\\nAverage processed text length: {df['Trial_Text'].str.len().mean():.0f} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2718dc7",
   "metadata": {},
   "source": [
    "## Step 7: Final Processing and Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6008f3",
   "metadata": {},
   "source": [
    "### 7.1: Drop Trial_ID Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3ad91a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping Trial_ID column...\n",
      "Columns: ['Date', 'Verdict', 'Offence', 'Year', 'Trial_Text']\n"
     ]
    }
   ],
   "source": [
    "print(\"Dropping Trial_ID column...\")\n",
    "df = df.drop(columns=[\"Trial_ID\"])\n",
    "print(f\"Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97224a60",
   "metadata": {},
   "source": [
    "### 7.2: Display Final Dataset Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88e7d4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "FINAL DATASET SUMMARY\n",
      "==================================================\n",
      "\n",
      "Shape: (49365, 5)\n",
      "Columns: ['Date', 'Verdict', 'Offence', 'Year', 'Trial_Text']\n",
      "\n",
      "Data types:\n",
      "Date          datetime64[ns]\n",
      "Verdict               object\n",
      "Offence               object\n",
      "Year                   int32\n",
      "Trial_Text            object\n",
      "dtype: object\n",
      "\n",
      "Verdict distribution:\n",
      "Verdict\n",
      "guilty       35487\n",
      "notGuilty    13878\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top 10 Offences:\n",
      "Offence\n",
      "theft            37033\n",
      "deception         2956\n",
      "violentTheft      2433\n",
      "royalOffences     2135\n",
      "sexual            1434\n",
      "breakingPeace     1319\n",
      "kill              1205\n",
      "miscellaneous      654\n",
      "damage             196\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Year range:\n",
      "Min: 1720, Max: 1913\n",
      "\n",
      "Missing values:\n",
      "Date          0\n",
      "Verdict       0\n",
      "Offence       0\n",
      "Year          0\n",
      "Trial_Text    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL DATASET SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nShape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nVerdict distribution:\")\n",
    "print(df[\"Verdict\"].value_counts())\n",
    "\n",
    "print(\"\\nTop 10 Offences:\")\n",
    "print(df[\"Offence\"].value_counts().head(10))\n",
    "\n",
    "print(\"\\nYear range:\")\n",
    "print(f\"Min: {df['Year'].min()}, Max: {df['Year'].max()}\")\n",
    "\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d4e3a1",
   "metadata": {},
   "source": [
    "### 7.3: Preview Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80bed50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Verdict</th>\n",
       "      <th>Offence</th>\n",
       "      <th>Year</th>\n",
       "      <th>Trial_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1750-01-17</td>\n",
       "      <td>notGuilty</td>\n",
       "      <td>theft</td>\n",
       "      <td>1750</td>\n",
       "      <td>john bowen indict ebruary hour twelve one morn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1750-01-17</td>\n",
       "      <td>guilty</td>\n",
       "      <td>theft</td>\n",
       "      <td>1750</td>\n",
       "      <td>nicholas bond william heyden late ulham indict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1750-01-17</td>\n",
       "      <td>notGuilty</td>\n",
       "      <td>theft</td>\n",
       "      <td>1750</td>\n",
       "      <td>thomas biggs indict steal one pair single chan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1750-01-17</td>\n",
       "      <td>guilty</td>\n",
       "      <td>theft</td>\n",
       "      <td>1750</td>\n",
       "      <td>elizabeth wanless otherwise newbey spinster in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1750-01-17</td>\n",
       "      <td>notGuilty</td>\n",
       "      <td>theft</td>\n",
       "      <td>1750</td>\n",
       "      <td>susannah lowe margaret richards widow indict s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date    Verdict Offence  Year  \\\n",
       "0 1750-01-17  notGuilty   theft  1750   \n",
       "1 1750-01-17     guilty   theft  1750   \n",
       "2 1750-01-17  notGuilty   theft  1750   \n",
       "3 1750-01-17     guilty   theft  1750   \n",
       "4 1750-01-17  notGuilty   theft  1750   \n",
       "\n",
       "                                          Trial_Text  \n",
       "0  john bowen indict ebruary hour twelve one morn...  \n",
       "1  nicholas bond william heyden late ulham indict...  \n",
       "2  thomas biggs indict steal one pair single chan...  \n",
       "3  elizabeth wanless otherwise newbey spinster in...  \n",
       "4  susannah lowe margaret richards widow indict s...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Verdict</th>\n",
       "      <th>Offence</th>\n",
       "      <th>Year</th>\n",
       "      <th>Trial_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76749</th>\n",
       "      <td>1723-05-30</td>\n",
       "      <td>notGuilty</td>\n",
       "      <td>theft</td>\n",
       "      <td>1723</td>\n",
       "      <td>darius humphreys parish whitechapel indict ste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76750</th>\n",
       "      <td>1723-05-30</td>\n",
       "      <td>guilty</td>\n",
       "      <td>theft</td>\n",
       "      <td>1723</td>\n",
       "      <td>john jones james hix ralph barrow alias arlow ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76751</th>\n",
       "      <td>1723-05-30</td>\n",
       "      <td>notGuilty</td>\n",
       "      <td>theft</td>\n",
       "      <td>1723</td>\n",
       "      <td>hannah coleman giles ields indict feloniously ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76752</th>\n",
       "      <td>1723-05-30</td>\n",
       "      <td>guilty</td>\n",
       "      <td>kill</td>\n",
       "      <td>1723</td>\n",
       "      <td>william hawksworth martin ields indict murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76753</th>\n",
       "      <td>1723-05-30</td>\n",
       "      <td>guilty</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>1723</td>\n",
       "      <td>john smith indict misdemeanour take four guine...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    Verdict        Offence  Year  \\\n",
       "76749 1723-05-30  notGuilty          theft  1723   \n",
       "76750 1723-05-30     guilty          theft  1723   \n",
       "76751 1723-05-30  notGuilty          theft  1723   \n",
       "76752 1723-05-30     guilty           kill  1723   \n",
       "76753 1723-05-30     guilty  miscellaneous  1723   \n",
       "\n",
       "                                              Trial_Text  \n",
       "76749  darius humphreys parish whitechapel indict ste...  \n",
       "76750  john jones james hix ralph barrow alias arlow ...  \n",
       "76751  hannah coleman giles ields indict feloniously ...  \n",
       "76752  william hawksworth martin ields indict murder ...  \n",
       "76753  john smith indict misdemeanour take four guine...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"First few rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nLast few rows:\")\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1710260b",
   "metadata": {},
   "source": [
    "## Step 8: Save Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ffd6f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset saved to: ../dataset/OBC_Cleaned.csv\n",
      "File size: 77.11 MB\n",
      "\n",
      "Total rows: 49365\n",
      "Total columns: 5\n",
      "\n",
      "Preprocessing pipeline complete!\n"
     ]
    }
   ],
   "source": [
    "output_path = \"../dataset/OBC_Cleaned.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Final dataset saved to: {output_path}\")\n",
    "print(f\"File size: {os.path.getsize(output_path) / (1024*1024):.2f} MB\")\n",
    "print(f\"\\nTotal rows: {len(df)}\")\n",
    "print(f\"Total columns: {len(df.columns)}\")\n",
    "print(\"\\nPreprocessing pipeline complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skripsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
